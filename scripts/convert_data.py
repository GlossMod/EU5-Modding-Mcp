#!/usr/bin/env python3
"""
å°† docs ä¸­çš„æ•°æ®æ–‡ä»¶è½¬æ¢ä¸º JSON æ ¼å¼ï¼Œä¾¿äºæ¨¡ç³ŠæŸ¥è¯¢
æ”¯æŒ: data_types/*.txt å’Œ *.log æ–‡ä»¶
"""

import json
import os
import re
from pathlib import Path
from typing import List, Dict, Any


def parse_data_type_file(file_path: str) -> List[Dict[str, Any]]:
    """
    è§£ææ•°æ®ç±»å‹æ–‡æœ¬æ–‡ä»¶ (data_types/*.txt)ï¼Œè¿”å›ç»“æ„åŒ–æ•°æ®åˆ—è¡¨
    
    Args:
        file_path: æ–‡æœ¬æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŒ…å«è§£ææ•°æ®çš„åˆ—è¡¨
    """
    entries = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä½¿ç”¨ "-----------------------" ä½œä¸ºåˆ†éš”ç¬¦åˆ†å‰²æ¡ç›®
    items = content.split('-----------------------\n')
    
    for item in items:
        item = item.strip()
        if not item:
            continue
        
        lines = item.split('\n')
        entry = {
            'name': '',
            'description': '',
            'definition_type': '',
            'return_type': '',
            'args': [],
            'type': 'data_type'
        }
        
        # ç¬¬ä¸€è¡Œé€šå¸¸æ˜¯åç§°ï¼ˆå¯èƒ½åŒ…å«å‚æ•°ï¼‰
        first_line = lines[0].strip()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å‡½æ•°å‚æ•°
        match = re.match(r'(\w+)\(\s*(.*?)\s*\)', first_line)
        if match:
            entry['name'] = match.group(1)
            args_str = match.group(2)
            if args_str:
                entry['args'] = [arg.strip() for arg in args_str.split(',')]
        else:
            entry['name'] = first_line
        
        # è§£æå…¶ä»–è¡Œ
        for line in lines[1:]:
            line = line.strip()
            if line.startswith('Description:'):
                entry['description'] = line.replace('Description:', '').strip()
            elif line.startswith('Definition type:'):
                entry['definition_type'] = line.replace('Definition type:', '').strip()
            elif line.startswith('Return type:'):
                entry['return_type'] = line.replace('Return type:', '').strip()
        
        if entry['name']:
            entries.append(entry)
    
    return entries


def parse_markdown_log_file(file_path: str) -> List[Dict[str, Any]]:
    """
    è§£æ Markdown æ ¼å¼çš„ log æ–‡ä»¶ (effects.log, triggers.log ç­‰)
    
    Args:
        file_path: log æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŒ…å«è§£ææ•°æ®çš„åˆ—è¡¨
    """
    entries = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å« ## æ ‡è®°ï¼ˆMarkdown h2ï¼‰
    if '##' not in content:
        return entries
    
    # æŒ‰ ## åˆ†å‰²æ¡ç›®
    items = re.split(r'\n##\s+', content)
    
    for item in items:
        if not item.strip():
            continue
        
        lines = item.split('\n')
        # ç¬¬ä¸€è¡Œæ˜¯åç§°
        name = lines[0].strip()
        
        if not name:
            continue
        
        entry = {
            'name': name,
            'description': '',
            'supported_scopes': [],
            'supported_targets': [],
            'type': 'effect'  # é»˜è®¤ï¼Œä¼šè¢«è¦†ç›–
        }
        
        # è§£ææè¿°å’Œå…¶ä»–å­—æ®µ
        description_lines = []
        for line in lines[1:]:
            line = line.rstrip()
            if line.startswith('**Supported Scopes**:'):
                scopes_str = line.replace('**Supported Scopes**:', '').strip()
                entry['supported_scopes'] = [s.strip() for s in scopes_str.split(',') if s.strip()]
            elif line.startswith('**Supported Targets**:'):
                targets_str = line.replace('**Supported Targets**:', '').strip()
                entry['supported_targets'] = [t.strip() for t in targets_str.split(',') if t.strip()]
            elif line and not line.startswith('**'):
                description_lines.append(line)
        
        entry['description'] = '\n'.join(description_lines).strip()
        
        if entry['name']:
            entries.append(entry)
    
    return entries


def parse_modifier_log_file(file_path: str) -> List[Dict[str, Any]]:
    """
    è§£æä¿®é¥°ç¬¦ log æ–‡ä»¶ (modifiers.log)
    æ ¼å¼: Tag: name, Categories: cat1, cat2, ...
    
    Args:
        file_path: log æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŒ…å«è§£ææ•°æ®çš„åˆ—è¡¨
    """
    entries = []
    
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    for line in lines:
        line = line.strip()
        if not line or line.startswith('Printing'):
            continue
        
        # è§£ææ ¼å¼: Tag: name, Categories: cat1, cat2, ...
        match = re.match(r'Tag:\s*([^,]+),\s*Categories:\s*(.*)', line)
        if match:
            name = match.group(1).strip()
            categories_str = match.group(2).strip()
            # æå–ç±»åˆ«ï¼ˆé€šå¸¸ä»¥é€—å·åˆ†éš”ï¼Œæœ€åå¯èƒ½æœ‰ All æˆ–ç©ºå€¼ï¼‰
            categories = [c.strip() for c in categories_str.split(',') if c.strip() and c.strip() != 'All']
            
            entry = {
                'name': name,
                'description': '',
                'categories': categories,
                'type': 'modifier'
            }
            
            entries.append(entry)
    
    return entries


def parse_log_file(file_path: str) -> List[Dict[str, Any]]:
    """
    æ ¹æ®æ–‡ä»¶å†…å®¹ç±»å‹é€‰æ‹©åˆé€‚çš„è§£æå™¨
    
    Args:
        file_path: log æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŒ…å«è§£ææ•°æ®çš„åˆ—è¡¨
    """
    file_name = Path(file_path).stem
    
    if file_name == 'modifiers':
        return parse_modifier_log_file(file_path)
    else:
        # effects, triggers, event_targets, on_actions, custom_localization
        return parse_markdown_log_file(file_path)


def convert_all_data():
    """
    è½¬æ¢æ‰€æœ‰æ•°æ®æ–‡ä»¶ (data_types/*.txt å’Œ *.log)ï¼Œç”Ÿæˆä¼˜åŒ–çš„ JSON æ–‡ä»¶
    """
    docs_dir = Path('e:/GitHub/GlossMod/EU5-Modifier-Mcp/docs')
    data_types_dir = docs_dir / 'data_types'
    output_dir = Path('e:/GitHub/GlossMod/EU5-Modifier-Mcp/mcp-data')
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    all_data = {}
    total_count = 0
    
    # å¤„ç† data_types æ–‡æœ¬æ–‡ä»¶
    print("ğŸ“„ å¤„ç† data_types æ–‡ä»¶:")
    for txt_file in sorted(data_types_dir.glob('*.txt')):
        print(f"  {txt_file.name}")
        
        entries = parse_data_type_file(str(txt_file))
        category = txt_file.stem
        
        all_data[category] = entries
        total_count += len(entries)
        
        # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆå•ç‹¬çš„ JSON æ–‡ä»¶
        output_file = output_dir / f"{category}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(entries, f, ensure_ascii=False, indent=2)
        
        print(f"    âœ“ {len(entries)} æ¡è®°å½•")
    
    # å¤„ç† log æ–‡ä»¶
    print("\nğŸ“‹ å¤„ç† log æ–‡ä»¶:")
    log_files = [
        'effects.log',
        'triggers.log',
        'event_targets.log',
        'on_actions.log',
        'modifiers.log',
        'custom_localization.log'
    ]
    
    for log_filename in log_files:
        log_file = docs_dir / log_filename
        if not log_file.exists():
            continue
        
        print(f"  {log_filename}")
        entries = parse_log_file(str(log_file))
        
        if entries:
            category = log_file.stem
            all_data[category] = entries
            total_count += len(entries)
            
            # ä¸ºæ¯ä¸ªç±»åˆ«ç”Ÿæˆå•ç‹¬çš„ JSON æ–‡ä»¶
            output_file = output_dir / f"{category}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(entries, f, ensure_ascii=False, indent=2)
            
            print(f"    âœ“ {len(entries)} æ¡è®°å½•")
    
    # ç”Ÿæˆç´¢å¼•æ–‡ä»¶ï¼šæŒ‰åç§°å»ºç«‹å¿«é€ŸæŸ¥æ‰¾è¡¨
    print("\nğŸ” ç”Ÿæˆç´¢å¼•...")
    index_by_name = {}
    for category, entries in all_data.items():
        for entry in entries:
            name = entry['name'].lower()
            if name not in index_by_name:
                index_by_name[name] = []
            
            # æ ¹æ®æ¡ç›®ç±»å‹æå–å…³é”®ä¿¡æ¯
            indexed_entry = {
                'category': category,
                'name': entry['name'],
                'description': entry.get('description', ''),
                'type': entry.get('type', 'unknown')
            }
            
            # æ ¹æ®æ¡ç›®ç±»å‹æ·»åŠ ç‰¹å®šå­—æ®µ
            if entry.get('type') == 'data_type':
                indexed_entry['definition_type'] = entry.get('definition_type', '')
                indexed_entry['return_type'] = entry.get('return_type', '')
                indexed_entry['args'] = entry.get('args', [])
            elif entry.get('type') in ['effect', 'trigger']:
                indexed_entry['supported_scopes'] = entry.get('supported_scopes', [])
                indexed_entry['supported_targets'] = entry.get('supported_targets', [])
            elif entry.get('type') == 'event_target':
                indexed_entry['input_scopes'] = entry.get('input_scopes', [])
                indexed_entry['output_scopes'] = entry.get('output_scopes', [])
            elif entry.get('type') == 'modifier':
                indexed_entry['categories'] = entry.get('categories', [])
            
            index_by_name[name].append(indexed_entry)
    
    index_file = output_dir / 'index.json'
    with open(index_file, 'w', encoding='utf-8') as f:
        json.dump(index_by_name, f, ensure_ascii=False, indent=2)
    print(f"  âœ“ ç”Ÿæˆç´¢å¼•æ–‡ä»¶ index.json ({len(index_by_name)} æ¡ç´¢å¼•)")
    
    # ç”Ÿæˆå…¨é‡æ•°æ®æ–‡ä»¶ç”¨äºæ¨¡ç³Šæœç´¢
    print("\nğŸ“¦ ç”Ÿæˆå…¨é‡æ•°æ®æ–‡ä»¶...")
    all_entries = []
    for category, entries in all_data.items():
        for entry in entries:
            entry_copy = entry.copy()
            entry_copy['category'] = category
            all_entries.append(entry_copy)
    
    all_data_file = output_dir / 'all_data.json'
    with open(all_data_file, 'w', encoding='utf-8') as f:
        json.dump(all_entries, f, ensure_ascii=False, indent=2)
    print(f"  âœ“ ç”Ÿæˆå…¨é‡æ•°æ®æ–‡ä»¶ all_data.json ({len(all_entries)} æ¡è®°å½•)")
    
    print("\n" + "="*60)
    print("âœ… æ•°æ®è½¬æ¢å®Œæˆï¼")
    print("="*60)
    print(f"ğŸ“Š æ€»è®¡: {total_count} æ¡è®°å½•")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶æ•°: {len(list(output_dir.glob('*.json')))}")


if __name__ == '__main__':
    convert_all_data()
